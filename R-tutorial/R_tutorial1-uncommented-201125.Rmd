---
title: "R Tutorial I: Data summary and wrangling via Tidyverse"
author: "Sunwoo Jeong"
date: "11/20/2019"
output: html_document
---

## Acknowledgement

This tutorial is based heavily on [Mike Frank's tutorial of Tidyverse](https://github.com/mcfrank/tidyverse-tutorial), which in turn is based on Hadley Wickham's [R for data scientists](http://r4ds.had.co.nz/). What I've mainly done is to adapt and translate the exercises in their materials so that we can work with linguistic data that we've gathered together throughout the course.

```{r setup, include=FALSE}
## You only need to do this once
install.packages("tidyverse")

## Call this in whenever you want to use associated packages such as ggplot2, tidyr, etc.
library(tidyverse)

knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
```

<!-- ----------------------------------------------------------------------- -->
# Goals and Introduction

By the end of this tutorial, you will know:

+ What "tidy data" is and why it's an awesome format
+ How to do some stuff with tidy data
+ How to get your data to be tidy (In particular, how to transform non-tidy output from Qualtrics into tidy format)

This intro will describe a few concepts that you will need to know, using the famous `iris` dataset that comes with `ggplot2`, as well as the aggregated data set from assignments 1 and 3.

## Data frames

The basic data structure we're working with is the data frame, or `tibble` (in the `tidyverse` reimplementation). 
Data frames have rows and columns, and each column has a distinct data type. The implementation in Python's `pandas` is distinct but most of the concepts are the same. 

`iris` is a data frame showing the measurements of a bunch of different instances of iris flowers from different species. (Sepals are the things outside the petals of the flowers that protect the petals while it's blooming, petals are the actual petals of the flower). Let's examine how the data set looks like, using the `head` command (and alternative: `summary`):

```{r}
head(iris)
summary(iris)
```

> **Exercise.** There are many ways to get a particular value of a variable in a data frame. You can use `$` to access a column, as in `iris$Sepal.Length` or you can treat the data frame as a matrix, e.g. `iris[1,1]` or even as a list, as in `iris[[1]]`. You can also mix numeric references and named references, e.g. `iris[["Sepal.Length"]]`. Turn to your neighbor (and/or google) and find a way to access the petal length of the third iris in the dataset (row 3).

```{r}
# write calls to the iris dataset that all return the same cell (third from the top, Petal Length).

iris$Sepal.Length[3]
head(iris)
```


Now let's take a look at the vowel/VOT data you collected from assignment 1 (Korean stops) and assignment 4 (Korean causatives/inchoatives and linguistic framing). You can call in the data using the `read.csv` command. You don't need to set the working directory as long as the .csv and the R script/markdown file are under the same folder. If you do need to set the working directory, try using relative paths rather than absolute ones.

```{r}
## load the data
# Your Korean stops (F0/VOT) data
datv <- read.csv('fall2020-stops-F0-combined.csv')
# A sample survey data
dats <- read.csv('qualtrics-processed-sample.csv')
# Your Korean causatives/inchoatives data
datc <- read.csv('fall2020-causative-pilot-results.csv')



## set working directory (absolute path like the one below not recommended)
setwd("/Users/sunwoojeong/Documents/ExpLing2019/R-tutorial/")
## relative paths
setwd("../R-tutorial/")
```

> **Exercise.** Examine what columns are in the dat dataset.

```{r}
# write a command that could give us an overview of the data structure of datv and datc
head(datv)
head(datc)
summary(datv)
```

## Tidy data

> “Tidy datasets are all alike, but every messy dataset is messy in its own way.” –– Hadley Wickham

Here's the basic idea: In tidy data, every row is a single **observation** (trial), and every column describes a **variable** with some **value** describing that trial. 

And if you know that data are formatted this way, then you can do amazing things, basically because you can take a uniform approach to the dataset. From R4DS:

"There’s a general advantage to picking one consistent way of storing data. If you have a consistent data structure, it’s easier to learn the tools that work with it because they have an underlying uniformity. There’s a specific advantage to placing variables in columns because it allows R’s vectorised nature to shine."

`iris` is a tidy dataset. Each row is an observation of an individual iris, each column is a different variable. `dat` is also a tidy dataset.

`dats` is not a tidy dataset. Let's make it tidy.

```{r}
dats_tidy <-
  dats %>% gather(trialtype, naturalness, -subj_gender, -subj_age, -subj_comm)

head(dats_tidy)
```


## Functions and Pipes

Everything you typically want to do in statistical programming uses **functions**. `mean` is a good example. `mean` takes one **argument**, a numeric vector. 

```{r}
mean(iris$Petal.Length)

head(iris)
```

We're going to call this **applying** the function `mean` to the variable `Petal.Length`.

Pipes are a way to write strings of functions more easily. They bring the first argument of the function to the beginning. So you can write:

```{r}
iris$Petal.Length %>% mean


```

That's not very useful yet, but when you start **nesting** functions, it gets better. 

```{r}
mean(unique(iris$Petal.Length))

iris$Petal.Length %>% 
  unique() %>% 
  mean(na.rm=TRUE)
```

or 

```{r}
round(mean(unique(iris$Petal.Length)), digits = 2)
iris$Petal.Length %>% unique %>% mean %>% round(digits = 2)

# indenting makes things even easier to read
iris$Petal.Length %>% 
  unique %>% 
  mean %>% 
  round(digits = 2)
```

This can be super helpful for writing strings of functions so that they are readable and distinct. 

We'll be doing a lot of piping of functions with multiple arguments later, and it will really help keep our syntax simple. 

> **Exercise.** Rewrite these commands using pipes and check that they do the same thing! (Or at least produce the same output). Unpiped version:

```{r}
length(unique(iris$Species)) # number of species
```

Piped version:

```{r}
# fill in the piped version!
iris$Species %>% unique %>%
  length 

summary(iris$Species)
```

> **Exercise.** Using piped functions, figure out the the mean of F0 startpoints and midpoints from datv. Also figure out number of speakers.

```{r}
# fill in the piped version!
head(datv)

datv$MidF0 %>% mean

datv$StartF0 %>% mean

mean(datv$MidF0)

```

> **Exercise.** Using piped functions, figure out the the mean blame rating from datc. Also figure out number of participants.

```{r}
# fill in the piped version!

datc$blame %>% mean

```


# Tidy Data Analysis with `dplyr`

Reference: [R4DS Chapter 5](http://r4ds.had.co.nz/transform.html)

Let's try manipulating our data using "verbs" from `dplyr`. We'll only take a look at four verbs (but there are many other useful ones):

+ `filter` - remove rows by some logical condition
+ `mutate` - create new columns 
+ `group_by` - group the data into subsets by some column
+ `summarize` - apply some function over columns in each group  


## Exploring and characterizing the dataset

Inspect the various variables before you start any analysis. You can use `summary`, or look at each variable by itself.
```{r}
# The datv data set
summary(datv)
summary(datv$stop)

unique(datv$sp)

datv$stop %>%
 unique %>%
 length

# The datc data set
summary(datc)
summary(datc$framing)
```

Alternatively, you can use interactive tools like `View` 

```{r}
View(datv)
View(datc)
```

## Filtering & Mutating

There are lots of reasons you might want to remove *rows* from your dataset, including getting rid of outliers, selecting subpopulations, etc. `filter` is a verb (function) that takes a data frame as its first argument, and then as its second takes the **condition** you want to filter on. 

So if you wanted to look only at F0 values between 140 to 280, you could do this. (Note that you can give two conditions, could also do `StartF0 > 140 & Start F0 < 280`). 

For non-numeric variables (e.g., certain factors), you can use the standard `==` and `!=` statements

Note that we're going to be using pipes with functions over data frames here. The way this works is that:

+ `dplyr` verbs always take the data frame as their first argument, and
+ because pipes pull out the first argument, the data frame just gets passed through successive operations
+ so you can read a pipe chain as "take this data frame and first do this, then do this, then do that."

This is essentially the huge insight of `dplyr`: you can chain verbs into readable and efficient sequences of operations over dataframes, provided 1) the verbs all have the same syntax (which they do) and 2) the data all have the same structure (which they do if they are tidy). 

An example of filtering:

```{r}
# datv: Just the F0 values between a certain range
datv %>%
  filter(StartF0 < 280,
         StartF0 > 140)

# datv: Just the female speakers
datv %>%
  filter(gender == "F")

# datc: Just the participants under 50s
datc %>%
  filter(age != "50s")

# If you want to actually save and work with the filtered data, assign it to a new data set (or change the name on the left the same as the one on the write, so that the changes can be overwritten)

datv_r <- datv %>%
  filter(StartF0 < 280,
         StartF0 > 140)

datv_f <- datv %>%
  filter(gender == "F")

datc2 <- datc %>%
  filter(age != "50s")

```

**Exercise.** Filter out only the p,b,k,g trials in the `stop` condition, and female speakers in the `sp` condition, and save that as a separate data frame.

```{r}


```

**Exercise.** Examine the EndF0 column of the datv data frame. Do you notice any problems? Fix it using filtering.

```{r}

head(datv)

datv$EndF0[1]

datv2 <- datv %>% filter(EndF0 != " --undefined--")


datv2$EndF0 <- as.double(datv2$EndF0)
head(datv2)
```


There are also times when you want to add or remove *columns*. You might want to remove columns to simplify the dataset. There's not much to simplify here, but if you wanted to do that, the verb is `select`. 

```{r}
datv %>%
  select(sp, gender, stop, word, vowel, MidF0) 

datv %>%
  select(-EndF0) 

# learn about this with ?select
```

Perhaps more useful is *adding columns*. You might do this perhaps to compute some kind of derived variable. `mutate` is the verb for these situations - it allows you to add a column. Let's add a slope column to our datc dataset.

```{r}
datv2 <- datv2 %>%
  mutate(slope = (StartF0 - EndF0)/(X.Duration.*1000))

head(datv2$slope)
```

## Standard psychological descriptives

We typically describe datasets at the level of subjects, not trials. We need two verbs to get a summary at the level of subjects: `group_by` and `summarise` (kiwi spelling). Grouping alone doesn't do much.

```{r}
datv2 %>%
  group_by(sp) 

# What does it actually do? Does it do what we want it to do?
```

All it does is add a grouping marker. 

What `summarise` does is to *apply a function* to a part of the dataset to create a new summary dataset. 

The general syntax: `summarise` takes multiple  `new_column_name = function_to_be_applied_to_data(data_column)` entries in a list. 

Where these two verbs shine is in combination. Because `summarise` applies functions to columns in your *grouped data*, not just to the whole dataset!

So we can group by age or condition or whatever else we want and then carry out the same procedure, and all of a sudden we are doing something extremely useful!

```{r}
datv2 %>%
  group_by(stop) %>%
  summarise(meanMidF0 = mean(MidF0))


datv_means <- datv2 %>%
  group_by(stop) %>%
  summarise(meanMidF0 = mean(MidF0))

datv_means
```

These summary data are typically very useful for plotting. (To be covered in next class!)

**Exercise.** For datv, generate a summary of F0 mean according to (i) stop type, (ii) stop type and speaker gender.

```{r}
datv_means2 <- datv2 %>%
  group_by(type) %>%
  summarise(meanMidF0 = mean(MidF0))

datv_means2

datv_means3 <- datv2 %>%
  group_by(type, gender) %>%
  summarise(meanMidF0 = mean(MidF0))

datv_means3
```

**Exercise.** For datc, generate a summary of liability rating according to morpheme and framing.

```{r}
datc_sum1 <- datc %>%
  group_by(morpheme, framing) %>%
  summarise(meanBlame = mean(blame))

datc_sum1
```

**Exercise.** In preparation for the next lab class, think of other summaries that may be useful in visualizing/analyzing the data from assignments 1 and 4.