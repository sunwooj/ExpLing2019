---
title: "R Tutorial I: Data summary and wrangling via Tidyverse"
author: "Sunwoo Jeong"
date: "11/20/2019"
output: html_document
---

## Acknowledgement

This tutorial is based heavily on [Mike Frank's tutorial of Tidyverse](https://github.com/mcfrank/tidyverse-tutorial), which in turn is based on Hadley Wickham's [R for data scientists](http://r4ds.had.co.nz/). What I've mainly done is to adapt and translate the exercises in their materials so that we can work with linguistic data that we've gathered together throughout the course.

```{r setup, include=FALSE}
## You only need to do this once
install.packages("tidyverse")

## Call this in whenever you want to use associated packages such as ggplot2, tidyr, etc.
library(tidyverse)

knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
```

<!-- ----------------------------------------------------------------------- -->
# Goals and Introduction

By the end of this tutorial, you will know:

+ What "tidy data" is and why it's an awesome format
+ How to do some stuff with tidy data
+ How to get your data to be tidy (In particular, how to transform non-tidy output from Qualtrics into tidy format)

This intro will describe a few concepts that you will need to know, using the famous `iris` dataset that comes with `ggplot2`, as well as the aggregated data set from assignments 1 and 3.

## Data frames

The basic data structure we're working with is the data frame, or `tibble` (in the `tidyverse` reimplementation). 
Data frames have rows and columns, and each column has a distinct data type. The implementation in Python's `pandas` is distinct but most of the concepts are the same. 

`iris` is a data frame showing the measurements of a bunch of different instances of iris flowers from different species. (Sepals are the things outside the petals of the flowers that protect the petals while it's blooming, petals are the actual petals of the flower). Let's examine how the data set looks like, using the `head` command:

```{r}
head(iris)
```

> **Exercise.** There are many ways to get a particular value of a variable in a data frame. You can use `$` to access a column, as in `iris$Sepal.Length` or you can treat the data frame as a matrix, e.g. `iris[1,1]` or even as a list, as in `iris[[1]]`. You can also mix numeric references and named references, e.g. `iris[["Sepal.Length"]]`. Turn to your neighbor (and/or google) and find a way to access the petal length of the third iris in the dataset (row 3).

```{r}
# fill me in with calls to the iris dataset that all return the same cell (third from the top, Petal Length).

iris$Sepal.Length[3]

```


Now let's take a look at our vowel data from assignment 1. You can call in the data using the `read.csv` command. You don't need to set the working directory as long as the .csv and the R script/markdown file are under the same folder. If you do need to set the working directory, try using relative paths rather than absolute ones.

```{r}
## load the data
datv <- read.csv('asmt1-korean-vowels.csv')
datc <- read.csv('asmt1-korean-stops.csv')

dats <- read.csv('qualtrics-processed-sample.csv')

## set working directory (absolute path like the one below not recommended)
setwd("/Users/sunwoojeong/Documents/ExpLing2019/R-tutorial/")
```

> **Exercise.** Examine what columns are in the dat dataset.

```{r}
# fill me in with a command that could give us an overview of the data structure of datv and datc

head(datv)
head(datc)

head(dats)

```

## Tidy data

> “Tidy datasets are all alike, but every messy dataset is messy in its own way.” –– Hadley Wickham

Here's the basic idea: In tidy data, every row is a single **observation** (trial), and every column describes a **variable** with some **value** describing that trial. 

And if you know that data are formatted this way, then you can do amazing things, basically because you can take a uniform approach to the dataset. From R4DS:

"There’s a general advantage to picking one consistent way of storing data. If you have a consistent data structure, it’s easier to learn the tools that work with it because they have an underlying uniformity. There’s a specific advantage to placing variables in columns because it allows R’s vectorised nature to shine."

`iris` is a tidy dataset. Each row is an observation of an individual iris, each column is a different variable. `dat` is also a tidy dataset.

`dats` is not a tidy dataset. Let's make it tidy.

```{r}
dats_tidy <-
  dats %>% gather(trialtype, naturalness, -subj_gender, -subj_age, -subj_comm)

head(dats_tidy)
```


## Functions and Pipes

Everything you typically want to do in statistical programming uses **functions**. `mean` is a good example. `mean` takes one **argument**, a numeric vector. 

```{r}
mean(iris$Petal.Length)
```

We're going to call this **applying** the function `mean` to the variable `Petal.Length`.

Pipes are a way to write strings of functions more easily. They bring the first argument of the function to the bedginning. So you can write:

```{r}
iris$Petal.Length %>% mean
```

That's not very useful yet, but when you start **nesting** functions, it gets better. 

```{r}
mean(unique(iris$Petal.Length))

iris$Petal.Length %>% unique() %>% mean(na.rm=TRUE)
```

or 

```{r}
round(mean(unique(iris$Petal.Length)), digits = 2)
iris$Petal.Length %>% unique %>% mean %>% round(digits = 2)

# indenting makes things even easier to read
iris$Petal.Length %>% 
  unique %>% 
  mean %>% 
  round(digits = 2)
```

This can be super helpful for writing strings of functions so that they are readable and distinct. 

We'll be doing a lot of piping of functions with multiple arguments later, and it will really help keep our syntax simple. 

> **Exercise.** Rewrite these commands using pipes and check that they do the same thing! (Or at least produce the same output). Unpiped version:

```{r}
length(unique(iris$Species)) # number of species
```

Piped version:

```{r}
# fill in the piped version!
iris$Species %>% 
  unique %>%
  length
```

> **Exercise.** Using piped functions, figure out the mean of height and the mean of F1, F2. F3, and F0 from datv. Also figure out number of heights (which likely reduces to number of subjects).

```{r}
# fill in the piped version!

datv$F0 %>%
  mean

datv$F1 %>%
  mean

datv$F2 %>%
  mean

datv$F3 %>%
  mean

datv$F1 %>%
  unique %>%
  mean

summary(datv$F0)

datv$ht %>% 
  unique %>%
  mean

datv$ht %>% 
  mean
```


# Tidy Data Analysis with `dplyr`

Reference: [R4DS Chapter 5](http://r4ds.had.co.nz/transform.html)

Let's try manipulateing our data using "verbs" from `dplyr`. We'll only take a look at four verbs (but there are many other useful ones):

+ `filter` - remove rows by some logical condition
+ `mutate` - create new columns 
+ `group_by` - group the data into subsets by some column
+ `summarize` - apply some function over columns in each group  


## Exploring and characterizing the dataset

Inspect the various variables before you start any analysis. You can use `summary`, or look at each variable by itself.
```{r}
summary(datc)
head(datc)

unique(datc$stop)

datc$word %>%
 unique %>%
 length
```

Alternatively, you can use interactive tools like `View` 

```{r}
View(datv)
```

## Filtering & Mutating

There are lots of reasons you might want to remove *rows* from your dataset, including getting rid of outliers, selecting subpopulations, etc. `filter` is a verb (function) that takes a data frame as its first argument, and then as its second takes the **condition** you want to filter on. 

So if you wanted to look only at people with heights over 164, you could do this. (Note you can give two conditions, could also do `ht > 164 & ht < 178`). (equivalent: `filter(datv, ht > 164, ht < 178)`)

Note that we're going to be using pipes with functions over data frames here. The way this works is that:

+ `dplyr` verbs always take the data frame as their first argument, and
+ because pipes pull out the first argument, the data frame just gets passed through successive operations
+ so you can read a pipe chain as "take this data frame and first do this, then do this, then do that."

This is essentially the huge insight of `dplyr`: you can chain verbs into readable and efficient sequences of operations over dataframes, provided 1) the verbs all have the same syntax (which they do) and 2) the data all have the same structure (which they do if they are tidy). 

OK, so filtering:

```{r}
datv %>%
  filter(ht > 164, 
         ht < 178) 

datv_av <-
  datv %>%
    filter(ht > 164, 
          ht < 178) 

head(datv_av)
```

**Exercise.** Filter out only the `iso` trial in the `wpos` condition, and 2nd vowel position (2) in the `vpos` condition, and save that as a separate data frame.

```{r}
datv %>%
  filter(wpos == "iso", 
         vpos == "2")

dat %>%
  filter(key_resp.keys != "None")

datv_iso2 <-
  datv %>%
  filter(wpos == "iso", 
         vpos == "2")

head(datv_iso2)

datv[datv$wpos == "iso" & datv$vpos == "2", ] # all the columns
```

**Exercise.** Examine the duration column of datc. Do you notice any problems? Fix it using filtering.

```{r}
datc %>%
  filter(duration != "NA")

datc_clean <-
  datc %>%
  filter(duration != "NA")
```


There are also times when you want to add or remove *columns*. You might want to remove columns to simplify the dataset. There's not much to simplify here, but if you wanted to do that, the verb is `select`. 

```{r}
datv %>%
  select(sp, ht, word, wpos, vtype, vpos, F0) 

datv %>%
  select(-group) 

# learn about this with ?select
```

Perhaps more useful is *adding columns*. You might do this perhaps to compute some kind of derived variable. `mutate` is the verb for these situations - it allows you to add a column. Let's add a slope column to our datc dataset.

```{r}
datc_clean <- datc_clean %>%
  mutate(slope = (datc_clean$v1F0on - datc_clean$v2F0off)/duration)

head(datc_clean$slope)
```

## Standard psychological descriptives

We typically describe datasets at the level of subjects, not trials. We need two verbs to get a summary at the level of subjects: `group_by` and `summarise` (kiwi spelling). Grouping alone doesn't do much.

```{r}
datv %>%
  group_by(sp) 

datv_g <- 
  datv %>%
  group_by(sp)

# What does it actually do? Does it do what we want it to do?
```

All it does is add a grouping marker. 

What `summarise` does is to *apply a function* to a part of the dataset to create a new summary dataset. 

The general syntax: `summarise` takes multiple  `new_column_name = function_to_be_applied_to_data(data_column)` entries in a list. 

Where these two verbs shine is in combination. Because `summarise` applies functions to columns in your *grouped data*, not just to the whole dataset!

So we can group by age or condition or whatever else we want and then carry out the same procedure, and all of a sudden we are doing something extremely useful!

```{r}
datv_means <- 
  datv %>%
  group_by(sp, wpos) %>%
  summarise(meanF0 = mean(F0))
datv_means
```

These summary data are typically very useful for plotting. (To be covered in next class!)

